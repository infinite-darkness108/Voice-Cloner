# tts_decode.py --backend pytorch --ngpu 0 --verbose 1 --out exp/train_pytorch_train_pytorch_tacotron2+spkemb/outputs_model.last1.avg.best_decode/dev/feats.2 --json exp/train_pytorch_train_pytorch_tacotron2+spkemb/outputs_model.last1.avg.best_decode/dev/split2utt/data.2.json --model exp/train_pytorch_train_pytorch_tacotron2+spkemb/results/model.last1.avg.best --config conf/decode.yaml 
# Started at Thu Nov  2 17:23:12 IST 2023
#
2023-11-02 17:23:12,582 (tts_decode:157) INFO: python path = /home/ananth/espnet/tools/RawNet/python/RawNet3:/home/ananth/espnet/tools/RawNet/python/RawNet3/models:
2023-11-02 17:23:12,583 (tts_decode:160) INFO: backend = pytorch
2023-11-02 17:23:18,471 (deterministic_utils:26) INFO: torch type check is disabled
2023-11-02 17:23:18,471 (asr_utils:693) INFO: reading a config file from exp/train_pytorch_train_pytorch_tacotron2+spkemb/results/model.json
2023-11-02 17:23:18,472 (tts:571) INFO: args: backend: pytorch
2023-11-02 17:23:18,472 (tts:571) INFO: args: backward_window: 1
2023-11-02 17:23:18,472 (tts:571) INFO: args: config: conf/decode.yaml
2023-11-02 17:23:18,472 (tts:571) INFO: args: config2: None
2023-11-02 17:23:18,472 (tts:571) INFO: args: config3: None
2023-11-02 17:23:18,472 (tts:571) INFO: args: debugmode: 1
2023-11-02 17:23:18,472 (tts:571) INFO: args: fastspeech_alpha: 1.0
2023-11-02 17:23:18,472 (tts:571) INFO: args: forward_window: 3
2023-11-02 17:23:18,472 (tts:571) INFO: args: json: exp/train_pytorch_train_pytorch_tacotron2+spkemb/outputs_model.last1.avg.best_decode/dev/split2utt/data.2.json
2023-11-02 17:23:18,472 (tts:571) INFO: args: maxlenratio: 10.0
2023-11-02 17:23:18,472 (tts:571) INFO: args: minlenratio: 0.0
2023-11-02 17:23:18,472 (tts:571) INFO: args: model: exp/train_pytorch_train_pytorch_tacotron2+spkemb/results/model.last1.avg.best
2023-11-02 17:23:18,472 (tts:571) INFO: args: model_conf: None
2023-11-02 17:23:18,472 (tts:571) INFO: args: ngpu: 0
2023-11-02 17:23:18,473 (tts:571) INFO: args: out: exp/train_pytorch_train_pytorch_tacotron2+spkemb/outputs_model.last1.avg.best_decode/dev/feats.2
2023-11-02 17:23:18,473 (tts:571) INFO: args: preprocess_conf: None
2023-11-02 17:23:18,473 (tts:571) INFO: args: save_durations: False
2023-11-02 17:23:18,473 (tts:571) INFO: args: save_focus_rates: False
2023-11-02 17:23:18,473 (tts:571) INFO: args: seed: 1
2023-11-02 17:23:18,473 (tts:571) INFO: args: threshold: 0.5
2023-11-02 17:23:18,473 (tts:571) INFO: args: use_att_constraint: False
2023-11-02 17:23:18,473 (tts:571) INFO: args: verbose: 1
2023-11-02 17:23:18,503 (tts:577) INFO: Tacotron2(
  (enc): Encoder(
    (embed): Embedding(27, 10, padding_idx=0)
    (convs): ModuleList(
      (0): Sequential(
        (0): Conv1d(10, 10, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.5, inplace=False)
      )
    )
    (blstm): LSTM(10, 5, batch_first=True, bidirectional=True)
  )
  (dec): Decoder(
    (att): AttLoc(
      (mlp_enc): Linear(in_features=522, out_features=128, bias=True)
      (mlp_dec): Linear(in_features=10, out_features=128, bias=False)
      (mlp_att): Linear(in_features=32, out_features=128, bias=False)
      (loc_conv): Conv2d(1, 32, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15), bias=False)
      (gvec): Linear(in_features=128, out_features=1, bias=True)
    )
    (lstm): ModuleList(
      (0): ZoneOutCell(
        (cell): LSTMCell(532, 10)
      )
    )
    (prenet): Prenet(
      (prenet): ModuleList(
        (0): Sequential(
          (0): Linear(in_features=80, out_features=10, bias=True)
          (1): ReLU()
        )
      )
    )
    (postnet): Postnet(
      (postnet): ModuleList(
        (0): Sequential(
          (0): Conv1d(80, 80, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (feat_out): Linear(in_features=532, out_features=160, bias=False)
    (prob_out): Linear(in_features=532, out_features=2, bias=True)
  )
  (taco2_loss): Tacotron2Loss(
    (l1_criterion): L1Loss()
    (mse_criterion): MSELoss()
    (bce_criterion): BCEWithLogitsLoss()
  )
)
2023-11-02 17:23:18,512 (tts:580) INFO: reading model parameters from exp/train_pytorch_train_pytorch_tacotron2+spkemb/results/model.last1.avg.best
/home/ananth/espnet/espnet/tts/pytorch_backend/tts.py:704: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
  spemb = torch.FloatTensor(data[1][0]).to(device)
[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.
2023-11-02 17:23:18,535 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:18,536 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:18,832 (tts:709) INFO: inference speed = 826.0 frames / sec.
2023-11-02 17:23:18,832 (tts:714) WARNING: output length reaches maximum length (339).
2023-11-02 17:23:18,832 (tts:716) INFO: (1/27) 339 (size: 26->260, focus rate: 0.606)
2023-11-02 17:23:20,880 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:20,881 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:21,284 (tts:709) INFO: inference speed = 839.3 frames / sec.
2023-11-02 17:23:21,284 (tts:714) WARNING: output length reaches maximum length (340).
2023-11-02 17:23:21,285 (tts:716) INFO: (2/27) 340 (size: 35->350, focus rate: 0.493)
2023-11-02 17:23:22,423 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:22,423 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:22,715 (tts:709) INFO: inference speed = 930.3 frames / sec.
2023-11-02 17:23:22,715 (tts:714) WARNING: output length reaches maximum length (341).
2023-11-02 17:23:22,715 (tts:716) INFO: (3/27) 341 (size: 28->280, focus rate: 0.688)
2023-11-02 17:23:23,648 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:23,649 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:23,950 (tts:709) INFO: inference speed = 983.1 frames / sec.
2023-11-02 17:23:23,950 (tts:714) WARNING: output length reaches maximum length (342).
2023-11-02 17:23:23,950 (tts:716) INFO: (4/27) 342 (size: 30->300, focus rate: 0.536)
2023-11-02 17:23:25,193 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:25,194 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:25,555 (tts:709) INFO: inference speed = 989.6 frames / sec.
2023-11-02 17:23:25,555 (tts:714) WARNING: output length reaches maximum length (343).
2023-11-02 17:23:25,564 (tts:716) INFO: (5/27) 343 (size: 37->370, focus rate: 0.532)
2023-11-02 17:23:26,731 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:26,733 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:26,977 (tts:709) INFO: inference speed = 892.5 frames / sec.
2023-11-02 17:23:26,977 (tts:714) WARNING: output length reaches maximum length (344).
2023-11-02 17:23:26,977 (tts:716) INFO: (6/27) 344 (size: 23->230, focus rate: 0.649)
2023-11-02 17:23:27,826 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:27,827 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:28,274 (tts:709) INFO: inference speed = 777.3 frames / sec.
2023-11-02 17:23:28,274 (tts:714) WARNING: output length reaches maximum length (345).
2023-11-02 17:23:28,274 (tts:716) INFO: (7/27) 345 (size: 35->350, focus rate: 0.678)
2023-11-02 17:23:29,510 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:29,511 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:29,881 (tts:709) INFO: inference speed = 749.9 frames / sec.
2023-11-02 17:23:29,881 (tts:714) WARNING: output length reaches maximum length (346).
2023-11-02 17:23:29,882 (tts:716) INFO: (8/27) 346 (size: 28->280, focus rate: 0.707)
2023-11-02 17:23:30,773 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:30,774 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:31,047 (tts:709) INFO: inference speed = 890.8 frames / sec.
2023-11-02 17:23:31,047 (tts:714) WARNING: output length reaches maximum length (347).
2023-11-02 17:23:31,047 (tts:716) INFO: (9/27) 347 (size: 25->250, focus rate: 0.619)
2023-11-02 17:23:31,841 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:31,842 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:32,124 (tts:709) INFO: inference speed = 759.9 frames / sec.
2023-11-02 17:23:32,124 (tts:714) WARNING: output length reaches maximum length (348).
2023-11-02 17:23:32,124 (tts:716) INFO: (10/27) 348 (size: 22->220, focus rate: 0.661)
2023-11-02 17:23:33,087 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:33,096 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:33,469 (tts:709) INFO: inference speed = 779.2 frames / sec.
2023-11-02 17:23:33,469 (tts:714) WARNING: output length reaches maximum length (349).
2023-11-02 17:23:33,469 (tts:716) INFO: (11/27) 349 (size: 30->300, focus rate: 0.597)
2023-11-02 17:23:34,446 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:34,446 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:34,858 (tts:709) INFO: inference speed = 867.4 frames / sec.
2023-11-02 17:23:34,858 (tts:714) WARNING: output length reaches maximum length (350).
2023-11-02 17:23:34,858 (tts:716) INFO: (12/27) 350 (size: 36->360, focus rate: 0.575)
2023-11-02 17:23:36,133 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:36,134 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:36,481 (tts:709) INFO: inference speed = 889.1 frames / sec.
2023-11-02 17:23:36,482 (tts:714) WARNING: output length reaches maximum length (351).
2023-11-02 17:23:36,482 (tts:716) INFO: (13/27) 351 (size: 32->320, focus rate: 0.630)
2023-11-02 17:23:37,687 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:37,689 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:38,119 (tts:709) INFO: inference speed = 644.3 frames / sec.
2023-11-02 17:23:38,119 (tts:714) WARNING: output length reaches maximum length (352).
2023-11-02 17:23:38,119 (tts:716) INFO: (14/27) 352 (size: 28->280, focus rate: 0.542)
2023-11-02 17:23:39,249 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:39,250 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:39,607 (tts:709) INFO: inference speed = 775.7 frames / sec.
2023-11-02 17:23:39,607 (tts:714) WARNING: output length reaches maximum length (353).
2023-11-02 17:23:39,616 (tts:716) INFO: (15/27) 353 (size: 28->280, focus rate: 0.661)
2023-11-02 17:23:40,545 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:40,546 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:41,022 (tts:709) INFO: inference speed = 780.3 frames / sec.
2023-11-02 17:23:41,022 (tts:714) WARNING: output length reaches maximum length (354).
2023-11-02 17:23:41,022 (tts:716) INFO: (16/27) 354 (size: 38->380, focus rate: 0.595)
2023-11-02 17:23:42,570 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:42,571 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:42,966 (tts:709) INFO: inference speed = 709.5 frames / sec.
2023-11-02 17:23:42,967 (tts:714) WARNING: output length reaches maximum length (355).
2023-11-02 17:23:42,967 (tts:716) INFO: (17/27) 355 (size: 29->290, focus rate: 0.592)
2023-11-02 17:23:43,918 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:43,919 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:44,131 (tts:709) INFO: inference speed = 946.3 frames / sec.
2023-11-02 17:23:44,131 (tts:714) WARNING: output length reaches maximum length (356).
2023-11-02 17:23:44,131 (tts:716) INFO: (18/27) 356 (size: 22->220, focus rate: 0.731)
2023-11-02 17:23:45,056 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:45,057 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:45,259 (tts:709) INFO: inference speed = 884.2 frames / sec.
2023-11-02 17:23:45,259 (tts:714) WARNING: output length reaches maximum length (357).
2023-11-02 17:23:45,259 (tts:716) INFO: (19/27) 357 (size: 19->190, focus rate: 0.763)
2023-11-02 17:23:46,240 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:46,241 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:46,604 (tts:709) INFO: inference speed = 681.8 frames / sec.
2023-11-02 17:23:46,604 (tts:714) WARNING: output length reaches maximum length (358).
2023-11-02 17:23:46,604 (tts:716) INFO: (20/27) 358 (size: 25->250, focus rate: 0.674)
2023-11-02 17:23:47,926 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:47,926 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:48,366 (tts:709) INFO: inference speed = 676.5 frames / sec.
2023-11-02 17:23:48,366 (tts:714) WARNING: output length reaches maximum length (359).
2023-11-02 17:23:48,366 (tts:716) INFO: (21/27) 359 (size: 30->300, focus rate: 0.645)
2023-11-02 17:23:49,434 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:49,434 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:49,767 (tts:709) INFO: inference speed = 775.7 frames / sec.
2023-11-02 17:23:49,767 (tts:714) WARNING: output length reaches maximum length (360).
2023-11-02 17:23:49,767 (tts:716) INFO: (22/27) 360 (size: 26->260, focus rate: 0.659)
2023-11-02 17:23:50,751 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:50,753 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:50,970 (tts:709) INFO: inference speed = 996.1 frames / sec.
2023-11-02 17:23:50,970 (tts:714) WARNING: output length reaches maximum length (361).
2023-11-02 17:23:50,971 (tts:716) INFO: (23/27) 361 (size: 23->230, focus rate: 0.632)
2023-11-02 17:23:51,579 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:51,580 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:51,782 (tts:709) INFO: inference speed = 1769.8 frames / sec.
2023-11-02 17:23:51,782 (tts:714) WARNING: output length reaches maximum length (362).
2023-11-02 17:23:51,782 (tts:716) INFO: (24/27) 362 (size: 37->370, focus rate: 0.607)
2023-11-02 17:23:52,333 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:52,334 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:52,532 (tts:709) INFO: inference speed = 1603.2 frames / sec.
2023-11-02 17:23:52,533 (tts:714) WARNING: output length reaches maximum length (363).
2023-11-02 17:23:52,533 (tts:716) INFO: (25/27) 363 (size: 33->330, focus rate: 0.581)
2023-11-02 17:23:53,081 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:53,082 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:53,211 (tts:709) INFO: inference speed = 1737.2 frames / sec.
2023-11-02 17:23:53,212 (tts:714) WARNING: output length reaches maximum length (364).
2023-11-02 17:23:53,212 (tts:716) INFO: (26/27) 364 (size: 23->230, focus rate: 0.703)
2023-11-02 17:23:53,629 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:53,630 (nets_utils:157) WARNING: Using make_pad_mask with a list of lengths is not tracable. If you try to trace this function with type(lengths) == list, please change the type of lengths to torch.LongTensor.
2023-11-02 17:23:53,885 (tts:709) INFO: inference speed = 1620.4 frames / sec.
2023-11-02 17:23:53,885 (tts:714) WARNING: output length reaches maximum length (365).
2023-11-02 17:23:53,885 (tts:716) INFO: (27/27) 365 (size: 42->420, focus rate: 0.549)
# Accounting: time=43 threads=1
# Ended (code 0) at Thu Nov  2 17:23:55 IST 2023, elapsed time 43 seconds
